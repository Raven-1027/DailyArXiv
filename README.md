# Daily Papers
The project automatically fetches the latest papers from arXiv based on keywords.

The subheadings in the README file represent the search keywords.

Only the most recent articles for each keyword are retained, up to a maximum of 100 papers.

You can click the 'Watch' button to receive daily email notifications.

Last update: 2025-04-06

## computational physics
| **Title** | **Date** | **Abstract** | **Comment** |
| --- | --- | --- | --- |
| **[Shock with Confidence: Formal Proofs of Correctness for Hyperbolic Partial Differential Equation Solvers](http://arxiv.org/abs/2503.13877v1)** | 2025-03-18 | <details><summary>Show</summary><p>First-order systems of hyperbolic partial differential equations (PDEs) occur ubiquitously throughout computational physics, commonly used in simulations of fluid turbulence, shock waves, electromagnetic interactions, and even general relativistic phenomena. Such equations are often challenging to solve numerically in the non-linear case, due to their tendency to form discontinuities even for smooth initial data, which can cause numerical algorithms to become unstable, violate conservation laws, or converge to physically incorrect solutions. In this paper, we introduce a new formal verification pipeline for such algorithms in Racket, which allows a user to construct a bespoke hyperbolic PDE solver for a specified equation system, generate low-level C code which verifiably implements that solver, and then produce formal proofs of various mathematical and physical correctness properties of the resulting implementation, including L^2 stability, flux conservation, and physical validity. We outline how these correctness proofs are generated, using a custom-built theorem-proving and automatic differentiation framework that fully respects the algebraic structure of floating-point arithmetic, and show how the resulting C code may either be used to run standalone simulations, or integrated into a larger computational multiphysics framework such as Gkeyll.</p></details> | <details><summary>13 pa...</summary><p>13 pages, prepared for submission to ACM</p></details> |
| **[DimOL: Dimensional Awareness as A New 'Dimension' in Operator Learning](http://arxiv.org/abs/2410.05894v3)** | 2025-03-17 | <details><summary>Show</summary><p>In the realm of computational physics, an enduring topic is the numerical solutions to partial differential equations (PDEs). Recently, the attention of researchers has shifted towards Neural Operator methods, renowned for their capability to approximate ``operators'' -- mappings from functions to functions. Despite the universal approximation theorem within neural operators, ensuring error bounds often requires employing numerous Fourier layers. However, what about lightweight models? In response to this question, we introduce DimOL (Dimension-aware Operator Learning), drawing insights from dimensional analysis. To implement DimOL, we propose the ProdLayer, which can be seamlessly integrated into FNO-based and Transformer-based PDE solvers, enhancing their ability to handle sum-of-products structures inherent in many physical systems. Empirically, DimOL models achieve up to 48% performance gain within the PDE datasets. Furthermore, by analyzing Fourier components' weights, we can symbolically discern the physical significance of each term. This sheds light on the opaque nature of neural networks, unveiling underlying physical principles.</p></details> |  |
| **[Direct Flow Simulations with Implicit Neural Representation of Complex Geometry](http://arxiv.org/abs/2503.08724v1)** | 2025-03-10 | <details><summary>Show</summary><p>Implicit neural representations have emerged as a powerful approach for encoding complex geometries as continuous functions. These implicit models are widely used in computer vision and 3D content creation, but their integration into scientific computing workflows, such as finite element or finite volume simulations, remains limited. One reason is that conventional simulation pipelines require explicit geometric inputs (meshes), forcing INR-based shapes to be converted to meshes--a step that introduces approximation errors, computational overhead, and significant manual effort. Immersed boundary methods partially alleviate this issue by allowing simulations on background grids without body-fitted meshes. However, they still require an explicit boundary description and can suffer from numerical artifacts, such as sliver cut cells. The shifted boundary method (SBM) eliminates the need for explicit geometry by using grid-aligned surrogate boundaries, making it inherently compatible with implicit shape representations. Here, we present a framework that directly couples neural implicit geometries with SBM to perform high-fidelity fluid flow simulations without any intermediate mesh generation. By leveraging neural network inference, our approach computes the surrogate boundary and distance vectors required by SBM on-the-fly directly from the INR, thus completely bypassing traditional geometry processing. We demonstrate this approach on canonical 2D and 3D flow benchmarks (lid-driven cavity flows) and complex geometries (gyroids, the Stanford bunny, and AI-generated shapes), achieving simulation accuracy comparable to conventional mesh-based methods. This work highlights a novel pathway for integrating AI-driven geometric representations into computational physics, establishing INRs as a versatile and scalable tool for simulations and removing a long-standing bottleneck in geometry handling.</p></details> | <details><summary>32 pa...</summary><p>32 pages,29 figures, Supplement at end</p></details> |
| **[Learning signals defined on graphs with optimal transport and Gaussian process regression](http://arxiv.org/abs/2410.15721v2)** | 2025-03-10 | <details><summary>Show</summary><p>In computational physics, machine learning has now emerged as a powerful complementary tool to explore efficiently candidate designs in engineering studies. Outputs in such supervised problems are signals defined on meshes, and a natural question is the extension of general scalar output regression models to such complex outputs. Changes between input geometries in terms of both size and adjacency structure in particular make this transition non-trivial. In this work, we propose an innovative strategy for Gaussian process regression where inputs are large and sparse graphs with continuous node attributes and outputs are signals defined on the nodes of the associated inputs. The methodology relies on the combination of regularized optimal transport, dimension reduction techniques, and the use of Gaussian processes indexed by graphs. In addition to enabling signal prediction, the main point of our proposal is to come with confidence intervals on node values, which is crucial for uncertainty quantification and active learning. Numerical experiments highlight the efficiency of the method to solve real problems in fluid dynamics and solid mechanics.</p></details> |  |
| **[Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient](http://arxiv.org/abs/2405.13152v4)** | 2025-03-04 | <details><summary>Show</summary><p>A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods.</p></details> | <details><summary>code:...</summary><p>code:https://github.com/kkk00714/ASPILin</p></details> |
| **[Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries](http://arxiv.org/abs/2408.02950v2)** | 2025-03-02 | <details><summary>Show</summary><p>Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multilayer Perceptrons (MLPs) in deep learning. KANs have already been integrated into various architectures, such as convolutional neural networks, graph neural networks, and transformers, and their potential has been assessed for predicting physical quantities. However, the combination of KANs with point-cloud-based neural networks (e.g., PointNet) for computational physics has not yet been explored. To address this, we present Kolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised deep learning framework for the prediction of incompressible steady-state fluid flow fields in irregular domains, where the predicted fields are a function of the geometry of the domains. In KA-PointNet, we implement shared KANs in the segmentation branch of the PointNet architecture. We utilize Jacobi polynomials to construct shared KANs. As a benchmark test case, we consider incompressible laminar steady-state flow over a cylinder, where the geometry of its cross-section varies over the data set. We investigate the performance of Jacobi polynomials with different degrees as well as special cases of Jacobi polynomials such as Legendre polynomials, Chebyshev polynomials of the first and second kinds, and Gegenbauer polynomials, in terms of the computational cost of training and accuracy of prediction of the test set. Additionally, we compare the performance of PointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared MLPs. It is observed that when the number of trainable parameters is approximately equal, PointNet with shared KANs (i.e., KA-PointNet) outperforms PointNet with shared MLPs. Moreover, KA-PointNet predicts the pressure and velocity distributions along the surface of cylinders more accurately, resulting in more precise computations of lift and drag.</p></details> |  |
| **[Recent Advances in Numerical Solutions for Hamilton-Jacobi PDEs](http://arxiv.org/abs/2502.20833v1)** | 2025-02-28 | <details><summary>Show</summary><p>Hamilton-Jacobi partial differential equations (HJ PDEs) play a central role in many applications such as economics, physics, and engineering. These equations describe the evolution of a value function which encodes valuable information about the system, such as action, cost, or level sets of a dynamic process. Their importance lies in their ability to model diverse phenomena, ranging from the propagation of fronts in computational physics to optimal decision-making in control systems. This paper provides a review of some recent advances in numerical methods to address challenges such as high-dimensionality, nonlinearity, and computational efficiency. By examining these developments, this paper sheds light on important techniques and emerging directions in the numerical solution of HJ PDEs.</p></details> |  |
| **[Blending Optimal Control and Biologically Plausible Learning for Noise-Robust Physical Neural Networks](http://arxiv.org/abs/2502.19053v1)** | 2025-02-26 | <details><summary>Show</summary><p>The rapidly increasing computational demands for artificial intelligence (AI) have spurred the exploration of computing principles beyond conventional digital computers. Physical neural networks (PNNs) offer efficient neuromorphic information processing by harnessing the innate computational power of physical processes; however, training their weight parameters is computationally expensive. We propose a training approach for substantially reducing this training cost. Our training approach merges an optimal control method for continuous-time dynamical systems with a biologically plausible training method--direct feedback alignment. In addition to the reduction of training time, this approach achieves robust processing even under measurement errors and noise without requiring detailed system information. The effectiveness was numerically and experimentally verified in an optoelectronic delay system. Our approach significantly extends the range of physical systems practically usable as PNNs.</p></details> | 28 pages, 10 figures |
| **[MadVoro: Parallel Construction of Voronoi Diagrams in Distributed Memory Systems](http://arxiv.org/abs/2502.14825v1)** | 2025-02-20 | <details><summary>Show</summary><p>Voronoi diagrams are essential geometrical structures with numerous applications, particularly astrophysics-driven finite volume methods. While serial algorithms for constructing these entities are well-established, parallel construction remains challenging. This is especially true in distributed memory systems, where each host manages only a subset of the input points. This process requires redistributing points across hosts and accurately computing the corresponding Voronoi cells. In this paper, we introduce a new distributed construction algorithm, which is implemented in our open-source C++ 3-dimensional Voronoi construction framework. Our approach leverages Delaunay triangulation as an intermediate step, which is then transformed into a Voronoi diagram. We introduce the algorithms we implemented for the precise construction and our load-balancing approach and compare the running time with other state-of-the-art frameworks. MadVoro is a versatile tool that can be applied in various scientific domains, such as mesh decomposition, computational physics, chemistry, and machine learning.</p></details> | <details><summary>will ...</summary><p>will be submitted to mnras in a few days, code available at https://github.com/maormizrachi/MadVoro</p></details> |
| **[Machine learning for modelling unstructured grid data in computational physics: a review](http://arxiv.org/abs/2502.09346v1)** | 2025-02-13 | <details><summary>Show</summary><p>Unstructured grid data are essential for modelling complex geometries and dynamics in computational physics. Yet, their inherent irregularity presents significant challenges for conventional machine learning (ML) techniques. This paper provides a comprehensive review of advanced ML methodologies designed to handle unstructured grid data in high-dimensional dynamical systems. Key approaches discussed include graph neural networks, transformer models with spatial attention mechanisms, interpolation-integrated ML methods, and meshless techniques such as physics-informed neural networks. These methodologies have proven effective across diverse fields, including fluid dynamics and environmental simulations. This review is intended as a guidebook for computational scientists seeking to apply ML approaches to unstructured grid data in their domains, as well as for ML researchers looking to address challenges in computational physics. It places special focus on how ML methods can overcome the inherent limitations of traditional numerical techniques and, conversely, how insights from computational physics can inform ML development. To support benchmarking, this review also provides a summary of open-access datasets of unstructured grid data in computational physics. Finally, emerging directions such as generative models with unstructured data, reinforcement learning for mesh generation, and hybrid physics-data-driven paradigms are discussed to inspire future advancements in this evolving field.</p></details> |  |
| **[MAD-NG, a standalone multiplatform tool for linear and non-linear optics design and optimisation](http://arxiv.org/abs/2412.16006v2)** | 2025-01-24 | <details><summary>Show</summary><p>The paper will provide an overview of the capabilities of the Methodical Accelerator Design Next Generation (MAD-NG) tool. MAD-NG is a standalone, all-in-one, multi-platform tool well-suited for linear and nonlinear optics design and optimization, and has already been used in large-scale studies such as HiLumi-LHC or FCC-ee. It embeds LuaJIT, an extremely fast tracing just-in-time compiler for the Lua programming language, delivering exceptional versatility and performance for the forefront of computational physics. The core of MAD-NG relies on the fast Generalized Truncated Power Series Algebra (GTPSA) library, which has been specially developed to handle many parameters and high-order differential algebra, including Lie map operators. This ecosystem offers powerful features for the analysis and optimization of linear and nonlinear optics, thanks to the fast parametric nonlinear normal forms and the polyvalent matching command. A few examples and results will complete this overview of the MAD-NG application.</p></details> | <details><summary>13 pa...</summary><p>13 pages, to be published in "Appears in the proceedings of the 14th International Computational Accelerator Physics Conference (ICAP 24), 2-5 October 2024, Germany"</p></details> |
| **[Modeling and simulations of high-density two-phase flows using projection-based Cahn-Hilliard Navier-Stokes equations](http://arxiv.org/abs/2406.17933v6)** | 2024-12-31 | <details><summary>Show</summary><p>Accurately modeling the dynamics of high-density ratio ($\mathcal{O}(10^5)$) two-phase flows is important for many material science and manufacturing applications. This work considers numerical simulations of molten metal oscillations in microgravity to analyze the interplay between surface tension and density ratio, a critical factor for terrestrial manufacturing applications. We present a projection-based computational framework for solving a thermodynamically-consistent Cahn-Hilliard Navier-Stokes equations for two-phase flows with large density ratios. The framework employs a modified version of the pressure-decoupled solver based on the Helmholtz-Hodge decomposition presented in Khanwale et al. [{\it A projection-based, semi-implicit time-stepping approach for the Cahn-Hilliard Navier-Stokes equations on adaptive octree meshes.}, Journal of Computational Physics 475 (2023): 111874]. We validate our numerical method on several canonical problems, including the capillary wave and single bubble rise problems. We also present a comprehensive convergence study to investigate the effect of mesh resolution, time-step, and interfacial thickness on droplet-shape oscillations. We further demonstrate the robustness of our framework by successfully simulating three distinct physical systems with extremely large density ratios ($10^4$-$10^5:1$), achieving results that have not been previously reported in the literature.</p></details> |  |
| **[Zephyr quantum-assisted hierarchical Calo4pQVAE for particle-calorimeter interactions](http://arxiv.org/abs/2412.04677v1)** | 2024-12-06 | <details><summary>Show</summary><p>With the approach of the High Luminosity Large Hadron Collider (HL-LHC) era set to begin particle collisions by the end of this decade, it is evident that the computational demands of traditional collision simulation methods are becoming increasingly unsustainable. Existing approaches, which rely heavily on first-principles Monte Carlo simulations for modeling event showers in calorimeters, are projected to require millions of CPU-years annually -- far exceeding current computational capacities. This bottleneck presents an exciting opportunity for advancements in computational physics by integrating deep generative models with quantum simulations. We propose a quantum-assisted hierarchical deep generative surrogate founded on a variational autoencoder (VAE) in combination with an energy conditioned restricted Boltzmann machine (RBM) embedded in the model's latent space as a prior. By mapping the topology of D-Wave's Zephyr quantum annealer (QA) into the nodes and couplings of a 4-partite RBM, we leverage quantum simulation to accelerate our shower generation times significantly. To evaluate our framework, we use Dataset 2 of the CaloChallenge 2022. Through the integration of classical computation and quantum simulation, this hybrid framework paves way for utilizing large-scale quantum simulations as priors in deep generative models.</p></details> | <details><summary>Neuri...</summary><p>Neurips ML4PS 2024. 5 Figs, 8 pp</p></details> |
| **[The lifex library version 2.0](http://arxiv.org/abs/2411.19624v1)** | 2024-11-29 | <details><summary>Show</summary><p>This article presents updates to lifex [Africa, SoftwareX (2022)], a C++ library for high-performance finite element simulations of multiphysics, multiscale and multidomain problems. In this release, we introduce an additional intergrid transfer method for non-matching multiphysics coupling on the same domain, significantly optimize nearest-neighbor point searches and interface coupling utilities, extend the support for 2D and mixed-dimensional problems, and provide improved facilities for input/output and simulation serialization and restart. These advancements also propagate to the previously released modules of lifex specifically designed for cardiac modeling and simulation, namely lifex-fiber [Africa et al., BMC Bioinformatics (2023)], lifex-ep [Africa et al., BMC Bioinformatics (2023)] and lifex-cfd [Africa et al., Computer Physics Communications (2024)]. The changes introduced in this release aim at consolidating lifex's position as a valuable and versatile tool for the simulation of multiphysics systems.</p></details> | 9 pages, 3 figures |
| **[Umbrella Reinforcement Learning -- computationally efficient tool for hard non-linear problems](http://arxiv.org/abs/2411.14117v1)** | 2024-11-21 | <details><summary>Show</summary><p>We report a novel, computationally efficient approach for solving hard nonlinear problems of reinforcement learning (RL). Here we combine umbrella sampling, from computational physics/chemistry, with optimal control methods. The approach is realized on the basis of neural networks, with the use of policy gradient. It outperforms, by computational efficiency and implementation universality, all available state-of-the-art algorithms, in application to hard RL problems with sparse reward, state traps and lack of terminal states. The proposed approach uses an ensemble of simultaneously acting agents, with a modified reward which includes the ensemble entropy, yielding an optimal exploration-exploitation balance.</p></details> |  |
| **[A Generalized Flux-Corrected Transport Algorithm I: A Finite-Difference Formulation](http://arxiv.org/abs/2411.12627v1)** | 2024-11-19 | <details><summary>Show</summary><p>This paper presents a generalized flux-corrected transport (FCT) algorithm, which is shown to be total variation diminishing under some conditions. The new algorithm has improved properties from the standpoint of use and analysis. Results show that the new FCT algorithm performs better than the older FCT algorithms and is comparable with other modern methods. This reformulation will also allow the FCT to be used effectively with exact or approximate Riemann solvers and as an implicit algorithm. This paper was originally submitted to the Journal of Computational Physics in 1990. It got lost in review. One reviewer loved the paper and suggested it be published immediately (he also died while it was in review). Another reviewer savaged the paper being from the FCT camp. The journal also went through several changes in management. Ultimately I declined to continue pursuing the paper as I had one infant child at the time and another on the way in 1995. Now 30 years on I am going to put this online.</p></details> | <details><summary>38 pa...</summary><p>38 pages and 18 figures</p></details> |
| **[Optimal Transport-Based Displacement Interpolation with Data Augmentation for Reduced Order Modeling of Nonlinear Dynamical Systems](http://arxiv.org/abs/2411.08750v1)** | 2024-11-13 | <details><summary>Show</summary><p>We present a novel reduced-order Model (ROM) that leverages optimal transport (OT) theory and displacement interpolation to enhance the representation of nonlinear dynamics in complex systems. While traditional ROM techniques face challenges in this scenario, especially when data (i.e., observational snapshots) is limited, our method addresses these issues by introducing a data augmentation strategy based on OT principles. The proposed framework generates interpolated solutions tracing geodesic paths in the space of probability distributions, enriching the training dataset for the ROM. A key feature of our approach is its ability to provide a continuous representation of the solution's dynamics by exploiting a virtual-to-real time mapping. This enables the reconstruction of solutions at finer temporal scales than those provided by the original data. To further improve prediction accuracy, we employ Gaussian Process Regression to learn the residual and correct the representation between the interpolated snapshots and the physical solution. We demonstrate the effectiveness of our methodology with atmospheric mesoscale benchmarks characterized by highly nonlinear, advection-dominated dynamics. Our results show improved accuracy and efficiency in predicting complex system behaviors, indicating the potential of this approach for a wide range of applications in computational physics and engineering.</p></details> |  |
| **[Predicting band structures for 2D Photonic Crystals via Deep Learning](http://arxiv.org/abs/2411.06063v1)** | 2024-11-09 | <details><summary>Show</summary><p>Photonic crystals (PhCs) are periodic dielectric structures that exhibit unique electromagnetic properties, such as the creation of band gaps where electromagnetic wave propagation is inhibited. Accurately predicting dispersion relations, which describe the frequency and direction of wave propagation, is vital for designing innovative photonic devices. However, traditional numerical methods, like the Finite Element Method (FEM), can encounter significant computational challenges due to the multiple scales present in photonic crystals, especially when calculating band structures across the entire Brillouin zone. To address this, we propose a supervised learning approach utilizing U-Net, along with transfer learning and Super-Resolution techniques, to forecast dispersion relations for 2D PhCs. Our model reduces computational expenses by producing high-resolution band structures from low-resolution data, eliminating the necessity for fine meshes throughout the Brillouin zone. The U-Net architecture enables the simultaneous prediction of multiple band functions, enhancing efficiency and accuracy compared to existing methods that handle each band function independently. Our findings demonstrate that the proposed model achieves high accuracy in predicting the initial band functions of 2D PhCs, while also significantly enhancing computational efficiency. This amalgamation of data-driven and traditional numerical techniques provides a robust framework for expediting the design and optimization of photonic crystals. The approach underscores the potential of integrating deep learning with established computational physics methods to tackle intricate multiscale problems, establishing a new benchmark for future PhC research and applications.</p></details> |  |
| **[Scalable physics-guided data-driven component model reduction for steady Navier-Stokes flow](http://arxiv.org/abs/2410.21583v1)** | 2024-10-28 | <details><summary>Show</summary><p>Computational physics simulation can be a powerful tool to accelerate industry deployment of new scientific technologies. However, it must address the challenge of computationally tractable, moderately accurate prediction at large industry scales, and training a model without data at such large scales. A recently proposed component reduced order modeling (CROM) tackles this challenge by combining reduced order modeling (ROM) with discontinuous Galerkin domain decomposition (DG-DD). While it can build a component ROM at small scales that can be assembled into a large scale system, its application is limited to linear physics equations. In this work, we extend CROM to nonlinear steady Navier-Stokes flow equation. Nonlinear advection term is evaluated via tensorial approach or empirical quadrature procedure. Application to flow past an array of objects at moderate Reynolds number demonstrates $\sim23.7$ times faster solutions with a relative error of $\sim 2.3\%$, even at scales $256$ times larger than the original problem.</p></details> | 6 pages, 1 figure |
| **[Discontinuous Galerkin scheme for elliptic equations on extremely stretched grids](http://arxiv.org/abs/2405.06120v2)** | 2024-10-24 | <details><summary>Show</summary><p>Discontinuous Galerkin (DG) methods for solving elliptic equations are gaining popularity in the computational physics community for their high-order spectral convergence and their potential for parallelization on computing clusters. However, problems in numerical relativity with extremely stretched grids, such as initial data problems for binary black holes that impose boundary conditions at large distances from the black holes, have proven challenging for DG methods. To alleviate this problem we have developed a primal DG scheme that is generically applicable to a large class of elliptic equations, including problems on curved and extremely stretched grids. The DG scheme accommodates two widely used initial data formulations in numerical relativity, namely the puncture formulation and the extended conformal thin-sandwich (XCTS) formulation. We find that our DG scheme is able to stretch the grid by a factor of $\sim 10^9$ and hence allows to impose boundary conditions at large distances. The scheme converges exponentially with resolution both for the smooth XCTS problem and for the nonsmooth puncture problem. With this method we are able to generate high-quality initial data for binary black hole problems using a parallelizable DG scheme. The code is publicly available in the open-source SpECTRE numerical relativity code.</p></details> | <details><summary>14 pa...</summary><p>14 pages, 10 figures. Results are reproducible with the ancillary input files</p></details> |
| **[Swift: High-Performance Sparse Tensor Contraction for Scientific Applications](http://arxiv.org/abs/2410.10094v1)** | 2024-10-14 | <details><summary>Show</summary><p>In scientific fields such as quantum computing, physics, chemistry, and machine learning, high dimensional data are typically represented using sparse tensors. Tensor contraction is a popular operation on tensors to exploit meaning or alter the input tensors. Tensor contraction is, however, computationally expensive and grows quadratically with the number of elements. For this reason, specialized algorithms have been created to only operate on the nonzero elements. Current sparse tensor contraction algorithms utilize sub-optimal data structures that perform unnecessary computations which increase execution time and the overall time complexity. We propose Swift, a novel algorithm for sparse tensor contraction that replaces the costly sorting with more efficient grouping, utilizes better data structures to represent tensors, and employs more memory-friendly hash table implementation. Swift is evaluated against the state-of-the-art sparse tensor contraction algorithm, demonstrating up to 20x speedup in various test cases and being able to handle imbalanced input tensors significantly better.</p></details> | 25 pages, 13 figures |
| **[Underwater Image Enhancement with Physical-based Denoising Diffusion Implicit Models](http://arxiv.org/abs/2409.18476v1)** | 2024-09-27 | <details><summary>Show</summary><p>Underwater vision is crucial for autonomous underwater vehicles (AUVs), and enhancing degraded underwater images in real-time on a resource-constrained AUV is a key challenge due to factors like light absorption and scattering, or the sufficient model computational complexity to resolve such factors. Traditional image enhancement techniques lack adaptability to varying underwater conditions, while learning-based methods, particularly those using convolutional neural networks (CNNs) and generative adversarial networks (GANs), offer more robust solutions but face limitations such as inadequate enhancement, unstable training, or mode collapse. Denoising diffusion probabilistic models (DDPMs) have emerged as a state-of-the-art approach in image-to-image tasks but require intensive computational complexity to achieve the desired underwater image enhancement (UIE) using the recent UW-DDPM solution. To address these challenges, this paper introduces UW-DiffPhys, a novel physical-based and diffusion-based UIE approach. UW-DiffPhys combines light-computation physical-based UIE network components with a denoising U-Net to replace the computationally intensive distribution transformation U-Net in the existing UW-DDPM framework, reducing complexity while maintaining performance. Additionally, the Denoising Diffusion Implicit Model (DDIM) is employed to accelerate the inference process through non-Markovian sampling. Experimental results demonstrate that UW-DiffPhys achieved a substantial reduction in computational complexity and inference time compared to UW-DDPM, with competitive performance in key metrics such as PSNR, SSIM, UCIQE, and an improvement in the overall underwater image quality UIQM metric. The implementation code can be found at the following repository: https://github.com/bachzz/UW-DiffPhys</p></details> |  |
| **[High-order Solution Transfer between Curved Triangular Meshes](http://arxiv.org/abs/1810.06806v2)** | 2024-09-24 | <details><summary>Show</summary><p>The problem of solution transfer between meshes arises frequently in computational physics, e.g. in Lagrangian methods where remeshing occurs. The interpolation process must be conservative, i.e. it must conserve physical properties, such as mass. We extend previous works -- which described the solution transfer process for straight sided unstructured meshes -- by considering high-order isoparametric meshes with curved elements. To facilitate solution transfer, we numerically integrate the product of shape functions via Green's theorem along the boundary of the intersection of two curved elements. We perform a numerical experiment and confirm the expected accuracy by transferring test fields across two families of meshes.</p></details> |  |
| **[Physics simulation capabilities of LLMs](http://arxiv.org/abs/2312.02091v2)** | 2024-09-02 | <details><summary>Show</summary><p>[Abridged abstract] Large Language Models (LLMs) can solve some undergraduate-level to graduate-level physics textbook problems and are proficient at coding. Combining these two capabilities could one day enable AI systems to simulate and predict the physical world. We present an evaluation of state-of-the-art (SOTA) LLMs on PhD-level to research-level computational physics problems. We condition LLM generation on the use of well-documented and widely-used packages to elicit coding capabilities in the physics and astrophysics domains. We contribute $\sim 50$ original and challenging problems in celestial mechanics (with REBOUND), stellar physics (with MESA), 1D fluid dynamics (with Dedalus) and non-linear dynamics (with SciPy). Since our problems do not admit unique solutions, we evaluate LLM performance on several soft metrics: counts of lines that contain different types of errors (coding, physics, necessity and sufficiency) as well as a more "educational" Pass-Fail metric focused on capturing the salient physical ingredients of the problem at hand. As expected, today's SOTA LLM (GPT4) zero-shot fails most of our problems, although about 40\% of the solutions could plausibly get a passing grade. About $70-90 \%$ of the code lines produced are necessary, sufficient and correct (coding \& physics). Physics and coding errors are the most common, with some unnecessary or insufficient lines. We observe significant variations across problem class and difficulty. We identify several failure modes of GPT4 in the computational physics domain. Our reconnaissance work provides a snapshot of current computational capabilities in classical physics and points to obvious improvement targets if AI systems are ever to reach a basic level of autonomy in physics simulation capabilities.</p></details> | <details><summary>Accep...</summary><p>Accepted for publication in Physica Scripta. Abridged abstract. 15 pages + appendix, 1 figure. Comments are welcome</p></details> |
| **[Operator SVD with Neural Networks via Nested Low-Rank Approximation](http://arxiv.org/abs/2402.03655v2)** | 2024-08-21 | <details><summary>Show</summary><p>Computing eigenvalue decomposition (EVD) of a given linear operator, or finding its leading eigenvalues and eigenfunctions, is a fundamental task in many machine learning and scientific computing problems. For high-dimensional eigenvalue problems, training neural networks to parameterize the eigenfunctions is considered as a promising alternative to the classical numerical linear algebra techniques. This paper proposes a new optimization framework based on the low-rank approximation characterization of a truncated singular value decomposition, accompanied by new techniques called \emph{nesting} for learning the top-$L$ singular values and singular functions in the correct order. The proposed method promotes the desired orthogonality in the learned functions implicitly and efficiently via an unconstrained optimization formulation, which is easy to solve with off-the-shelf gradient-based optimization algorithms. We demonstrate the effectiveness of the proposed optimization framework for use cases in computational physics and machine learning.</p></details> | <details><summary>36 pa...</summary><p>36 pages, 7 figures. ICML 2024. Almost identical to the conference version, except a few updates for fixing typos and mistakes</p></details> |
| **[SparseAuto: An Auto-Scheduler for Sparse Tensor Computations Using Recursive Loop Nest Restructuring](http://arxiv.org/abs/2311.09549v3)** | 2024-08-19 | <details><summary>Show</summary><p>Automated code generation and performance enhancements for sparse tensor algebra have become essential in many real-world applications, such as quantum computing, physical simulations, computational chemistry, and machine learning. General sparse tensor algebra compilers are not always versatile enough to generate asymptotically optimal code for sparse tensor contractions. This paper shows how to generate asymptotically better schedules for complex sparse tensor expressions using kernel fission and fusion. We present generalized loop restructuring transformations to reduce asymptotic time complexity and memory footprint. Furthermore, we present an auto-scheduler that uses a partially ordered set (poset)-based cost model that uses both time and auxiliary memory complexities to prune the search space of schedules. In addition, we highlight the use of Satisfiability Module Theory (SMT) solvers in sparse auto-schedulers to approximate the Pareto frontier of better schedules to the smallest number of possible schedules, with user-defined constraints available at compile-time. Finally, we show that our auto-scheduler can select better-performing schedules and generate code for them. Our results show that the auto-scheduler provided schedules achieve orders-of-magnitude speedup compared to the code generated by the Tensor Algebra Compiler (TACO) for several computations on different real-world tensors.</p></details> |  |
| **[Kolmogorov Arnold Informed neural network: A physics-informed deep learning framework for solving forward and inverse problems based on Kolmogorov Arnold Networks](http://arxiv.org/abs/2406.11045v2)** | 2024-08-04 | <details><summary>Show</summary><p>AI for partial differential equations (PDEs) has garnered significant attention, particularly with the emergence of Physics-informed neural networks (PINNs). The recent advent of Kolmogorov-Arnold Network (KAN) indicates that there is potential to revisit and enhance the previously MLP-based PINNs. Compared to MLPs, KANs offer interpretability and require fewer parameters. PDEs can be described in various forms, such as strong form, energy form, and inverse form. While mathematically equivalent, these forms are not computationally equivalent, making the exploration of different PDE formulations significant in computational physics. Thus, we propose different PDE forms based on KAN instead of MLP, termed Kolmogorov-Arnold-Informed Neural Network (KINN) for solving forward and inverse problems. We systematically compare MLP and KAN in various numerical examples of PDEs, including multi-scale, singularity, stress concentration, nonlinear hyperelasticity, heterogeneous, and complex geometry problems. Our results demonstrate that KINN significantly outperforms MLP regarding accuracy and convergence speed for numerous PDEs in computational solid mechanics, except for the complex geometry problem. This highlights KINN's potential for more efficient and accurate PDE solutions in AI for PDEs.</p></details> |  |
| **[An electrical engineering perspective on naturality in computational physics](http://arxiv.org/abs/1809.01002v3)** | 2024-07-19 | <details><summary>Show</summary><p>We look at computational physics from an electrical engineering perspective and suggest that several concepts of mathematics, not so well-established in computational physics literature, present themselves as opportunities in the field. We discuss elliptic complexes and highlight the category theoretical background and its role as a unifying language between algebraic topology, differential geometry, and modelling software design. In particular, the ubiquitous concept of naturality is central. Natural differential operators have functorial analogues on the cochains of triangulated manifolds. In order to establish this correspondence, we derive formulas involving simplices and barycentric coordinates, defining discrete vector fields and a discrete Lie derivative as a result of a discrete analogue of Cartan's magic formula. This theorem is the main mathematical result of the paper.</p></details> | <details><summary>This ...</summary><p>This is a new manuscript that has evolved from the earlier versions</p></details> |
| **[Group Projected Subspace Pursuit for Block Sparse Signal Reconstruction: Convergence Analysis and Applications](http://arxiv.org/abs/2407.07707v2)** | 2024-07-14 | <details><summary>Show</summary><p>In this paper, we present a convergence analysis of the Group Projected Subspace Pursuit (GPSP) algorithm proposed by He et al. [HKL+23] (Group Projected subspace pursuit for IDENTification of variable coefficient differential equations (GP-IDENT), Journal of Computational Physics, 494, 112526) and extend its application to general tasks of block sparse signal recovery. We prove that when the sampling matrix satisfies the Block Restricted Isometry Property (BRIP) with a sufficiently small Block Restricted Isometry Constant (BRIC), GPSP exactly recovers the true block sparse signals. When the observations are noisy, this convergence property of GPSP remains valid if the magnitude of true signal is sufficiently large. GPSP selects the features by subspace projection criterion (SPC) for candidate inclusion and response magnitude criterion (RMC) for candidate exclusion. We compare these criteria with counterparts of other state-of-the-art greedy algorithms. Our theoretical analysis and numerical ablation studies reveal that SPC is critical to the superior performances of GPSP, and that RMC can enhance the robustness of feature identification when observations contain noises. We test and compare GPSP with other methods in diverse settings, including heterogeneous random block matrices, inexact observations, face recognition, and PDE identification. We find that GPSP outperforms the other algorithms in most cases for various levels of block sparsity and block sizes, justifying its effectiveness for general applications.</p></details> | 35 pages |
| **[Stable Weight Updating: A Key to Reliable PDE Solutions Using Deep Learning](http://arxiv.org/abs/2407.07375v1)** | 2024-07-10 | <details><summary>Show</summary><p>Background: Deep learning techniques, particularly neural networks, have revolutionized computational physics, offering powerful tools for solving complex partial differential equations (PDEs). However, ensuring stability and efficiency remains a challenge, especially in scenarios involving nonlinear and time-dependent equations. Methodology: This paper introduces novel residual-based architectures, namely the Simple Highway Network and the Squared Residual Network, designed to enhance stability and accuracy in physics-informed neural networks (PINNs). These architectures augment traditional neural networks by incorporating residual connections, which facilitate smoother weight updates and improve backpropagation efficiency. Results: Through extensive numerical experiments across various examples including linear and nonlinear, time-dependent and independent PDEs we demonstrate the efficacy of the proposed architectures. The Squared Residual Network, in particular, exhibits robust performance, achieving enhanced stability and accuracy compared to conventional neural networks. These findings underscore the potential of residual-based architectures in advancing deep learning for PDEs and computational physics applications.</p></details> |  |
| **[Weak baselines and reporting biases lead to overoptimism in machine learning for fluid-related partial differential equations](http://arxiv.org/abs/2407.07218v1)** | 2024-07-09 | <details><summary>Show</summary><p>One of the most promising applications of machine learning (ML) in computational physics is to accelerate the solution of partial differential equations (PDEs). The key objective of ML-based PDE solvers is to output a sufficiently accurate solution faster than standard numerical methods, which are used as a baseline comparison. We first perform a systematic review of the ML-for-PDE solving literature. Of articles that use ML to solve a fluid-related PDE and claim to outperform a standard numerical method, we determine that 79% (60/76) compare to a weak baseline. Second, we find evidence that reporting biases, especially outcome reporting bias and publication bias, are widespread. We conclude that ML-for-PDE solving research is overoptimistic: weak baselines lead to overly positive results, while reporting biases lead to underreporting of negative results. To a large extent, these issues appear to be caused by factors similar to those of past reproducibility crises: researcher degrees of freedom and a bias towards positive results. We call for bottom-up cultural changes to minimize biased reporting as well as top-down structural reforms intended to reduce perverse incentives for doing so.</p></details> |  |
| **[Solidarity of Gibbs Samplers: the spectral gap](http://arxiv.org/abs/2304.02109v2)** | 2024-07-09 | <details><summary>Show</summary><p>Gibbs samplers are preeminent Markov chain Monte Carlo algorithms used in computational physics and statistical computing. Yet, their most fundamental properties, such as relations between convergence characteristics of their various versions, are not well understood. In this paper we prove the solidarity of their spectral gaps: if any of the random scan or $d!$ deterministic scans has a~spectral gap then all of them have. Our methods rely on geometric interpretation of the Gibbs samplers as alternating projection algorithms and analysis of the rate of convergence in the von Neumann--Halperin method of cyclic alternating projections. In addition, we provide a quantitative result: if the spectral gap of the random scan Gibbs sampler scales polynomially with dimension, so does the spectral gap of any of the deterministic scans.</p></details> |  |
| **[A Review of Differentiable Simulators](http://arxiv.org/abs/2407.05560v1)** | 2024-07-08 | <details><summary>Show</summary><p>Differentiable simulators continue to push the state of the art across a range of domains including computational physics, robotics, and machine learning. Their main value is the ability to compute gradients of physical processes, which allows differentiable simulators to be readily integrated into commonly employed gradient-based optimization schemes. To achieve this, a number of design decisions need to be considered representing trade-offs in versatility, computational speed, and accuracy of the gradients obtained. This paper presents an in-depth review of the evolving landscape of differentiable physics simulators. We introduce the foundations and core components of differentiable simulators alongside common design choices. This is followed by a practical guide and overview of open-source differentiable simulators that have been used across past research. Finally, we review and contextualize prominent applications of differentiable simulation. By offering a comprehensive review of the current state-of-the-art in differentiable simulation, this work aims to serve as a resource for researchers and practitioners looking to understand and integrate differentiable physics within their research. We conclude by highlighting current limitations as well as providing insights into future directions for the field.</p></details> | <details><summary>Accep...</summary><p>Accepted to IEEE Access</p></details> |
| **[Riemannian Newton methods for energy minimization problems of Kohn-Sham type](http://arxiv.org/abs/2307.13820v2)** | 2024-06-27 | <details><summary>Show</summary><p>This paper is devoted to the numerical solution of constrained energy minimization problems arising in computational physics and chemistry such as the Gross-Pitaevskii and Kohn-Sham models. In particular, we introduce the Riemannian Newton methods on the infinite-dimensional Stiefel and Grassmann manifolds. We study the geometry of these two manifolds, its impact on the Newton algorithms, and present expressions of the Riemannian Hessians in the infinite-dimensional setting, which are suitable for variational spatial discretizations. A series of numerical experiments illustrates the performance of the methods and demonstrates its supremacy compared to other well-established schemes such as the self-consistent field iteration and gradient descent schemes.</p></details> |  |
| **[Spin-Wave Voices: Sonification of Nanoscale Spin Waves as an Engagement and Research Tool](http://arxiv.org/abs/2405.03506v3)** | 2024-06-21 | <details><summary>Show</summary><p>Magnonics is an emerging research field that addresses the use of spin waves (magnons), purely magnetic waves, for information transport and processing. Spin waves are a potential replacement for electric current in modern computational devices that would make them more compact and energy efficient. The field is yet little known, even among physicists. Additionally, with the development of new measuring techniques and computational physics, the obtained magnetic data becomes more complex, in some cases including 3D vector fields and time-resolution. This work presents an approach to the audio-visual representation of the spin waves and discusses its use as a tool for science communication exhibits and possible data analysis tool. The work also details an instance of such an exhibit presented at the annual international digital art exhibition Ars Electronica Festival in 2022.</p></details> | <details><summary>Accep...</summary><p>Accepted to The 29th International Conference on Auditory Display (ICAD 2024) conference proceedings</p></details> |
| **[Delegated-Query Oblivious Transfer and its Practical Applications](http://arxiv.org/abs/2406.15063v1)** | 2024-06-21 | <details><summary>Show</summary><p>Databases play a pivotal role in the contemporary World Wide Web and the world of cloud computing. Unfortunately, numerous privacy violations have recently garnered attention in the news. To enhance database privacy, we consider Oblivious Transfer (OT), an elegant cryptographic technology. Our observation reveals that existing research in this domain primarily concentrates on theoretical cryptographic applications, overlooking various practical aspects: - OTs assume parties have direct access to databases. Our "1-out-of-2 Delegated-Query OT" enables parties to privately query a database, without direct access. - With the rise of cloud computing, physically separated databases may no longer remain so. Our "1-out-of-2 Delegated-Query Multi-Receiver OT" protects privacy in such evolving scenarios. - Research often ignores the limitations of thin clients, e.g., Internet of Things devices. To address this, we propose a compiler that transforms any 1-out-of-n OT into a thin client version.</p></details> |  |
| **[A Discrete Exterior Calculus of Bundle-valued Forms](http://arxiv.org/abs/2406.05383v1)** | 2024-06-08 | <details><summary>Show</summary><p>The discretization of Cartan's exterior calculus of differential forms has been fruitful in a variety of theoretical and practical endeavors: from computational electromagnetics to the development of Finite-Element Exterior Calculus, the development of structure-preserving numerical tools satisfying exact discrete equivalents to Stokes' theorem or the de Rham complex for the exterior derivative have found numerous applications in computational physics. However, there has been a dearth of effort in establishing a more general discrete calculus, this time for differential forms with values in vector bundles over a combinatorial manifold equipped with a connection. In this work, we propose a discretization of the exterior covariant derivative of bundle-valued differential forms. We demonstrate that our discrete operator mimics its continuous counterpart, satisfies the Bianchi identities on simplicial cells, and contrary to previous attempts at its discretization, ensures numerical convergence to its exact evaluation with mesh refinement under mild assumptions.</p></details> | <details><summary>58 pa...</summary><p>58 pages, 20 figures, Fix erroneous line break</p></details> |
| **[Reflectionless discrete perfectly matched layers for higher-order finite difference schemes](http://arxiv.org/abs/2306.13189v2)** | 2024-05-29 | <details><summary>Show</summary><p>This paper introduces discrete-holomorphic Perfectly Matched Layers (PMLs) specifically designed for high-order finite difference (FD) discretizations of the scalar wave equation. In contrast to standard PDE-based PMLs, the proposed method achieves the remarkable outcome of completely eliminating numerical reflections at the PML interface, in practice achieving errors at the level of machine precision. Our approach builds upon the ideas put forth in a recent publication [Journal of Computational Physics 381 (2019): 91-109] expanding the scope from the standard second-order FD method to arbitrary high-order schemes. This generalization uses additional localized PML variables to accommodate the larger stencils employed. We establish that the numerical solutions generated by our proposed schemes exhibit an exponential decay rate as they propagate within the PML domain. To showcase the effectiveness of our method, we present a variety of numerical examples, including waveguide problems. These examples highlight the importance of employing high-order schemes to effectively address and minimize undesired numerical dispersion errors, emphasizing the practical advantages and applicability of our approach.</p></details> |  |
| **[Infrastructure Engineering: A Still Missing, Undervalued Role in the Research Ecosystem](http://arxiv.org/abs/2405.10473v2)** | 2024-05-28 | <details><summary>Show</summary><p>Research has become increasingly reliant on software, serving as the driving force behind bioinformatics, high performance computing, physics, machine learning and artificial intelligence, to name a few. While substantial progress has been made in advocating for the research software engineer, a kind of software engineer that typically works directly on software and associated assets that go into research, little attention has been placed on the workforce behind research infrastructure and innovation, namely compilers and compatibility tool development, orchestration and scheduling infrastructure, developer environments, container technologies, and workflow managers. As economic incentives are moving toward different models of cloud computing and innovating is required to develop new paradigms that represent the best of both worlds, an effort called "converged computing," the need for such a role is not just ideal, but essential for the continued success of science. While scattered staff in non-traditional roles have found time to work on some facets of this space, the lack of a larger workforce and incentive to support it has led to the scientific community falling behind. In this article we will highlight the importance of this missing layer, providing examples of how a missing role of infrastructure engineer has led to inefficiencies in the interoperability, portability, and reproducibility of science. We suggest that an inability to allocate, provide resources for, and sustain individuals to work explicitly on these technologies could lead to possible futures that are sub-optimal for the continued success of our scientific communities.</p></details> | <details><summary>13 pa...</summary><p>13 pages, 1 figure, 1 table</p></details> |
| **[Computing Transition Pathways for the Study of Rare Events Using Deep Reinforcement Learning](http://arxiv.org/abs/2404.05905v1)** | 2024-04-08 | <details><summary>Show</summary><p>Understanding the transition events between metastable states in complex systems is an important subject in the fields of computational physics, chemistry and biology. The transition pathway plays an important role in characterizing the mechanism underlying the transition, for example, in the study of conformational changes of bio-molecules. In fact, computing the transition pathway is a challenging task for complex and high-dimensional systems. In this work, we formulate the path-finding task as a cost minimization problem over a particular path space. The cost function is adapted from the Freidlin-Wentzell action functional so that it is able to deal with rough potential landscapes. The path-finding problem is then solved using a actor-critic method based on the deep deterministic policy gradient algorithm (DDPG). The method incorporates the potential force of the system in the policy for generating episodes and combines physical properties of the system with the learning process for molecular systems. The exploitation and exploration nature of reinforcement learning enables the method to efficiently sample the transition events and compute the globally optimal transition pathway. We illustrate the effectiveness of the proposed method using three benchmark systems including an extended Mueller system and the Lennard-Jones system of seven particles.</p></details> |  |
| **[Reweighted Manifold Learning of Collective Variables from Enhanced Sampling Simulations](http://arxiv.org/abs/2207.14554v2)** | 2024-04-03 | <details><summary>Show</summary><p>Enhanced sampling methods are indispensable in computational physics and chemistry, where atomistic simulations cannot exhaustively sample the high-dimensional configuration space of dynamical systems due to the sampling problem. A class of such enhanced sampling methods works by identifying a few slow degrees of freedom, termed collective variables (CVs), and enhancing the sampling along these CVs. Selecting CVs to analyze and drive the sampling is not trivial and often relies on physical and chemical intuition. Despite routinely circumventing this issue using manifold learning to estimate CVs directly from standard simulations, such methods cannot provide mappings to a low-dimensional manifold from enhanced sampling simulations as the geometry and density of the learned manifold are biased. Here, we address this crucial issue and provide a general reweighting framework based on anisotropic diffusion maps for manifold learning that takes into account that the learning data set is sampled from a biased probability distribution. We consider manifold learning methods based on constructing a Markov chain describing transition probabilities between high-dimensional samples. We show that our framework reverts the biasing effect yielding CVs that correctly describe the equilibrium density. This advancement enables the construction of low-dimensional CVs using manifold learning directly from data generated by enhanced sampling simulations. We call our framework reweighted manifold learning. We show that it can be used in many manifold learning techniques on data from both standard and enhanced sampling simulations.</p></details> | Published version |
| **[A Physics-driven GraphSAGE Method for Physical Process Simulations Described by Partial Differential Equations](http://arxiv.org/abs/2403.08569v1)** | 2024-03-13 | <details><summary>Show</summary><p>Physics-informed neural networks (PINNs) have successfully addressed various computational physics problems based on partial differential equations (PDEs). However, while tackling issues related to irregularities like singularities and oscillations, trained solutions usually suffer low accuracy. In addition, most current works only offer the trained solution for predetermined input parameters. If any change occurs in input parameters, transfer learning or retraining is required, and traditional numerical techniques also need an independent simulation. In this work, a physics-driven GraphSAGE approach (PD-GraphSAGE) based on the Galerkin method and piecewise polynomial nodal basis functions is presented to solve computational problems governed by irregular PDEs and to develop parametric PDE surrogate models. This approach employs graph representations of physical domains, thereby reducing the demands for evaluated points due to local refinement. A distance-related edge feature and a feature mapping strategy are devised to help training and convergence for singularity and oscillation situations, respectively. The merits of the proposed method are demonstrated through a couple of cases. Moreover, the robust PDE surrogate model for heat conduction problems parameterized by the Gaussian random field source is successfully established, which not only provides the solution accurately but is several times faster than the finite element method in our experiments.</p></details> | <details><summary>18 pa...</summary><p>18 pages,11 figures, 3 tables</p></details> |
| **[Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels](http://arxiv.org/abs/2402.03838v2)** | 2024-03-11 | <details><summary>Show</summary><p>Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molecular datasets, where the input graphs have a few tens of nodes. The efficiency of the SWWL kernel is then illustrated on graph regression in computational fluid dynamics and solid mechanics, where the input graphs are made up of tens of thousands of nodes.</p></details> |  |
| **[Separable Physics-informed Neural Networks for Solving the BGK Model of the Boltzmann Equation](http://arxiv.org/abs/2403.06342v1)** | 2024-03-10 | <details><summary>Show</summary><p>In this study, we introduce a method based on Separable Physics-Informed Neural Networks (SPINNs) for effectively solving the BGK model of the Boltzmann equation. While the mesh-free nature of PINNs offers significant advantages in handling high-dimensional partial differential equations (PDEs), challenges arise when applying quadrature rules for accurate integral evaluation in the BGK operator, which can compromise the mesh-free benefit and increase computational costs. To address this, we leverage the canonical polyadic decomposition structure of SPINNs and the linear nature of moment calculation, achieving a substantial reduction in computational expense for quadrature rule application. The multi-scale nature of the particle density function poses difficulties in precisely approximating macroscopic moments using neural networks. To improve SPINN training, we introduce the integration of Gaussian functions into SPINNs, coupled with a relative loss approach. This modification enables SPINNs to decay as rapidly as Maxwellian distributions, thereby enhancing the accuracy of macroscopic moment approximations. The relative loss design further ensures that both large and small-scale features are effectively captured by the SPINNs. The efficacy of our approach is demonstrated through a series of five numerical experiments, including the solution to a challenging 3D Riemann problem. These results highlight the potential of our novel method in efficiently and accurately addressing complex challenges in computational physics.</p></details> |  |
| **[High-performance finite elements with MFEM](http://arxiv.org/abs/2402.15940v1)** | 2024-02-25 | <details><summary>Show</summary><p>The MFEM (Modular Finite Element Methods) library is a high-performance C++ library for finite element discretizations. MFEM supports numerous types of finite element methods and is the discretization engine powering many computational physics and engineering applications across a number of domains. This paper describes some of the recent research and development in MFEM, focusing on performance portability across leadership-class supercomputing facilities, including exascale supercomputers, as well as new capabilities and functionality, enabling a wider range of applications. Much of this work was undertaken as part of the Department of Energy's Exascale Computing Project (ECP) in collaboration with the Center for Efficient Exascale Discretizations (CEED).</p></details> | 19 pages, 19 figures |
| **[CodPy: a Python library for numerics, machine learning, and statistics](http://arxiv.org/abs/2402.07084v1)** | 2024-02-11 | <details><summary>Show</summary><p>This monograph offers an introduction to a collection of numerical algorithms implemented in the library CodPy (an acronym that stands for the Curse Of Dimensionality in PYthon), which has found widespread applications across various areas, including machine learning, statistics, and computational physics. We develop here a strategy based on the theory of reproducing kernel Hilbert spaces (RKHS) and the theory of optimal transport. Initially designed for mathematical finance, this library has since been enhanced and broadened to be applicable to problems arising in engineering and industry. In order to present the general principles and techniques employed in CodPy and its applications, we have structured this monograph into two main parts. First of all, we focus on the fundamental principles of kernel-based representations of data and solutions, also that the presentation therein is supplemented with illustrative examples only. Next, we discuss the application of these principles to many classes of concrete problems, spanning from the numerical approximation of partial differential equations to (supervised, unsupervised) machine learning, extending to generative methods with a focus on stochastic aspects.</p></details> | 135 pages |
| **[Least-Squares Neural Network (LSNN) Method For Linear Advection-Reaction Equation: Discontinuity Interface](http://arxiv.org/abs/2301.06156v4)** | 2024-02-05 | <details><summary>Show</summary><p>We studied the least-squares ReLU neural network (LSNN) method for solving linear advection-reaction equation with discontinuous solution in [Cai, Zhiqiang, Jingshuang Chen, and Min Liu. ``Least-squares ReLU neural network (LSNN) method for linear advection-reaction equation.'' Journal of Computational Physics 443 (2021), 110514]. The method is based on a least-squares formulation and uses a new class of approximating functions: ReLU neural network (NN) functions. A critical and additional component of the LSNN method, differing from other NN-based methods, is the introduction of a properly designed and physics preserved discrete differential operator. In this paper, we study the LSNN method for problems with discontinuity interfaces. First, we show that ReLU NN functions with depth $\lceil \log_2(d+1)\rceil+1$ can approximate any $d$-dimensional step function on a discontinuity interface generated by a vector field as streamlines with any prescribed accuracy. By decomposing the solution into continuous and discontinuous parts, we prove theoretically that discretization error of the LSNN method using ReLU NN functions with depth $\lceil \log_2(d+1)\rceil+1$ is mainly determined by the continuous part of the solution provided that the solution jump is constant. Numerical results for both two- and three-dimensional test problems with various discontinuity interfaces show that the LSNN method with enough layers is accurate and does not exhibit the common Gibbs phenomena along discontinuity interfaces.</p></details> | 30 pages |
| **[Multi-fidelity physics constrained neural networks for dynamical systems](http://arxiv.org/abs/2402.02031v1)** | 2024-02-03 | <details><summary>Show</summary><p>Physics-constrained neural networks are commonly employed to enhance prediction robustness compared to purely data-driven models, achieved through the inclusion of physical constraint losses during the model training process. However, one of the major challenges of physics-constrained neural networks consists of the training complexity especially for high-dimensional systems. In fact, conventional physics-constrained models rely on singular-fidelity data necessitating the assessment of physical constraints within high-dimensional fields, which introduces computational difficulties. Furthermore, due to the fixed input size of the neural networks, employing multi-fidelity training data can also be cumbersome. In this paper, we propose the Multi-Scale Physics-Constrained Neural Network (MSPCNN), which offers a novel methodology for incorporating data with different levels of fidelity into a unified latent space through a customised multi-fidelity autoencoder. Additionally, multiple decoders are concurrently trained to map latent representations of inputs into various fidelity physical spaces. As a result, during the training of predictive models, physical constraints can be evaluated within low-fidelity spaces, yielding a trade-off between training efficiency and accuracy. In addition, unlike conventional methods, MSPCNN also manages to employ multi-fidelity data to train the predictive model. We assess the performance of MSPCNN in two fluid dynamics problems, namely a two-dimensional Burgers' system and a shallow water system. Numerical results clearly demonstrate the enhancement of prediction accuracy and noise robustness when introducing physical constraints in low-fidelity fields. On the other hand, as expected, the training complexity can be significantly reduced by computing physical constraint loss in the low-fidelity field rather than the high-fidelity one.</p></details> |  |
| **[Optimal control approach for moving bottom detection in one-dimensional shallow waters by surface measurements](http://arxiv.org/abs/2401.17239v1)** | 2024-01-30 | <details><summary>Show</summary><p>We consider the Boussinesq-Peregrine (BP) system as described by Lannes [Lannes, D. (2013). The water waves problem: mathematical analysis and asymptotics (Vol. 188). American Mathematical Soc.], within the shallow water regime, and study the inverse problem of determining the time and space variations of the channel bottom profile, from measurements of the wave profile and its velocity on the free surface. A well-posedness result within a Sobolev framework for (BP), considering a time dependent bottom, is presented. Then, the inverse problem is reformulated as a nonlinear PDEconstrained optimization one. An existence result of the minimum, under constraints on the admissible set of bottoms, is presented. Moreover, an implementation of the gradient descent approach, via the adjoint method, is considered. For solving numerically both, the forward (BP) and its adjoint system, we derive a universal and low-dissipation scheme, which contains non-conservative products. The scheme is based on the FORCE-{\alpha} method proposed in [Toro, E. F., Saggiorato, B., Tokareva, S., and Hidalgo, A. (2020). Low-dissipation centred schemes for hyperbolic equations in conservative and non-conservative form. Journal of Computational Physics, 416, 109545]. Finally, we implement this methodology to recover three different bottom profiles; a smooth bottom, a discontinuous one, and a continuous profile with a large gradient. We compare with two classical discretizations for (BP) and the adjoint system. These results corroborate the effectiveness of the proposed methodology to recover bottom profiles.</p></details> | 30 pages, 13 figures |
| **[A quatum inspired neural network for geometric modeling](http://arxiv.org/abs/2401.01801v2)** | 2024-01-28 | <details><summary>Show</summary><p>By conceiving physical systems as 3D many-body point clouds, geometric graph neural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcased promising performance. In particular, their effective message-passing mechanics make them adept at modeling molecules and crystalline materials. However, current geometric GNNs only offer a mean-field approximation of the many-body system, encapsulated within two-body message passing, thus falling short in capturing intricate relationships within these geometric graphs. To address this limitation, tensor networks, widely employed by computational physics to handle manybody systems using high-order tensors, have been introduced. Nevertheless, integrating these tensorized networks into the message-passing framework of GNNs faces scalability and symmetry conservation (e.g., permutation and rotation) challenges. In response, we introduce an innovative equivariant Matrix Product State (MPS)-based message-passing strategy, through achieving an efficient implementation of the tensor contraction operation. Our method effectively models complex many-body relationships, suppressing mean-field approximations, and captures symmetries within geometric graphs. Importantly, it seamlessly replaces the standard message-passing and layer-aggregation modules intrinsic to geometric GNNs. We empirically validate the superior accuracy of our approach on benchmark tasks, including predicting classical Newton systems and quantum tensor Hamiltonian matrices. To our knowledge, our approach represents the inaugural utilization of parameterized geometric tensor networks.</p></details> |  |
| **[Accelerated Sampling of Rare Events using a Neural Network Bias Potential](http://arxiv.org/abs/2401.06936v1)** | 2024-01-13 | <details><summary>Show</summary><p>In the field of computational physics and material science, the efficient sampling of rare events occurring at atomic scale is crucial. It aids in understanding mechanisms behind a wide range of important phenomena, including protein folding, conformal changes, chemical reactions and materials diffusion and deformation. Traditional simulation methods, such as Molecular Dynamics and Monte Carlo, often prove inefficient in capturing the timescale of these rare events by brute force. In this paper, we introduce a practical approach by combining the idea of importance sampling with deep neural networks (DNNs) that enhance the sampling of these rare events. In particular, we approximate the variance-free bias potential function with DNNs which is trained to maximize the probability of rare event transition under the importance potential function. This method is easily scalable to high-dimensional problems and provides robust statistical guarantees on the accuracy of the estimated probability of rare event transition. Furthermore, our algorithm can actively generate and learn from any successful samples, which is a novel improvement over existing methods. Using a 2D system as a test bed, we provide comparisons between results obtained from different training strategies, traditional Monte Carlo sampling and numerically solved optimal bias potential function under different temperatures. Our numerical results demonstrate the efficacy of the DNN-based importance sampling of rare events.</p></details> |  |
| **[$$-Diffusion: A diffusion-based density estimation framework for computational physics](http://arxiv.org/abs/2312.08153v1)** | 2023-12-13 | <details><summary>Show</summary><p>In physics, density $\rho(\cdot)$ is a fundamentally important scalar function to model, since it describes a scalar field or a probability density function that governs a physical process. Modeling $\rho(\cdot)$ typically scales poorly with parameter space, however, and quickly becomes prohibitively difficult and computationally expensive. One promising avenue to bypass this is to leverage the capabilities of denoising diffusion models often used in high-fidelity image generation to parameterize $\rho(\cdot)$ from existing scientific data, from which new samples can be trivially sampled from. In this paper, we propose $\rho$-Diffusion, an implementation of denoising diffusion probabilistic models for multidimensional density estimation in physics, which is currently in active development and, from our results, performs well on physically motivated 2D and 3D density functions. Moreover, we propose a novel hashing technique that allows $\rho$-Diffusion to be conditioned by arbitrary amounts of physical parameters of interest.</p></details> | <details><summary>6 pag...</summary><p>6 pages, 2 figures, accepted for publication at the NeurIPS 2023 workshop "Machine Learning and the Physical Sciences"</p></details> |
| **[Numerical spectra of the Laplacian for line bundles on Calabi-Yau hypersurfaces](http://arxiv.org/abs/2305.08901v2)** | 2023-12-04 | <details><summary>Show</summary><p>We give the first numerical calculation of the spectrum of the Laplacian acting on bundle-valued forms on a Calabi-Yau three-fold. Specifically, we show how to compute the approximate eigenvalues and eigenmodes of the Dolbeault Laplacian acting on bundle-valued $(p,q)$-forms on K\"ahler manifolds. We restrict our attention to line bundles over complex projective space and Calabi-Yau hypersurfaces therein. We give three examples. For two of these, $\mathbb{P}^3$ and a Calabi-Yau one-fold (a torus), we compare our numerics with exact results available in the literature and find complete agreement. For the third example, the Fermat quintic three-fold, there are no known analytic results, so our numerical calculations are the first of their kind. The resulting spectra pass a number of non-trivial checks that arise from Serre duality and the Hodge decomposition. The outputs of our algorithm include all the ingredients one needs to compute physical Yukawa couplings in string compactifications.</p></details> | <details><summary>52 pa...</summary><p>52 pages, 6 figures; v2 - corrected typo in quintic equation</p></details> |
| **[Equivariant Transformer is all you need](http://arxiv.org/abs/2310.13222v1)** | 2023-10-20 | <details><summary>Show</summary><p>Machine learning, deep learning, has been accelerating computational physics, which has been used to simulate systems on a lattice. Equivariance is essential to simulate a physical system because it imposes a strong induction bias for the probability distribution described by a machine learning model. This reduces the risk of erroneous extrapolation that deviates from data symmetries and physical laws. However, imposing symmetry on the model sometimes occur a poor acceptance rate in self-learning Monte-Carlo (SLMC). On the other hand, Attention used in Transformers like GPT realizes a large model capacity. We introduce symmetry equivariant attention to SLMC. To evaluate our architecture, we apply it to our proposed new architecture on a spin-fermion model on a two-dimensional lattice. We find that it overcomes poor acceptance rates for linear models and observe the scaling law of the acceptance rate as in the large language models with Transformers.</p></details> | <details><summary>7 pag...</summary><p>7 pages, 4 figures, contribution for the 40th International Symposium on Lattice Field Theory (Lattice 2023), July 31st - August 4th, 2023, Fermi National Accelerator Laboratory</p></details> |
| **[Non-isothermal nonlocal phase-field models with a double-obstacle potential](http://arxiv.org/abs/2310.07861v1)** | 2023-10-11 | <details><summary>Show</summary><p>Phase-field models are a popular choice in computational physics to describe complex dynamics of substances with multiple phases and are widely used in various applications. We present nonlocal non-isothermal phase-field models of Cahn-Hilliard and Allen-Cahn types involving a nonsmooth double-well obstacle potential. Mathematically, in a weak form, the model translates to a system of variational inequalities coupled to a temperature evolution equation. We demonstrate that under certain conditions and with a careful choice of the nonlocal operator one can obtain a model that allows for sharp interfaces in the solution that evolve in time, which is a desirable property in many applications. This can be contrasted to the diffuse-interface local models that can not resolve sharp interfaces. We present the well-posedness analysis of the models, discuss an appropriate numerical discretization scheme, and supplement our findings with several numerical experiments.</p></details> |  |
| **[Nonlinear model order reduction for problems with microstructure using mesh informed neural networks](http://arxiv.org/abs/2309.07815v1)** | 2023-09-14 | <details><summary>Show</summary><p>Many applications in computational physics involve approximating problems with microstructure, characterized by multiple spatial scales in their data. However, these numerical solutions are often computationally expensive due to the need to capture fine details at small scales. As a result, simulating such phenomena becomes unaffordable for many-query applications, such as parametrized systems with multiple scale-dependent features. Traditional projection-based reduced order models (ROMs) fail to resolve these issues, even for second-order elliptic PDEs commonly found in engineering applications. To address this, we propose an alternative nonintrusive strategy to build a ROM, that combines classical proper orthogonal decomposition (POD) with a suitable neural network (NN) model to account for the small scales. Specifically, we employ sparse mesh-informed neural networks (MINNs), which handle both spatial dependencies in the solutions and model parameters simultaneously. We evaluate the performance of this strategy on benchmark problems and then apply it to approximate a real-life problem involving the impact of microcirculation in transport phenomena through the tissue microenvironment.</p></details> |  |
| **[Padding-free Convolution based on Preservation of Differential Characteristics of Kernels](http://arxiv.org/abs/2309.06370v1)** | 2023-09-12 | <details><summary>Show</summary><p>Convolution is a fundamental operation in image processing and machine learning. Aimed primarily at maintaining image size, padding is a key ingredient of convolution, which, however, can introduce undesirable boundary effects. We present a non-padding-based method for size-keeping convolution based on the preservation of differential characteristics of kernels. The main idea is to make convolution over an incomplete sliding window "collapse" to a linear differential operator evaluated locally at its central pixel, which no longer requires information from the neighbouring missing pixels. While the underlying theory is rigorous, our final formula turns out to be simple: the convolution over an incomplete window is achieved by convolving its nearest complete window with a transformed kernel. This formula is computationally lightweight, involving neither interpolation or extrapolation nor restrictions on image and kernel sizes. Our method favours data with smooth boundaries, such as high-resolution images and fields from physics. Our experiments include: i) filtering analytical and non-analytical fields from computational physics and, ii) training convolutional neural networks (CNNs) for the tasks of image classification, semantic segmentation and super-resolution reconstruction. In all these experiments, our method has exhibited visible superiority over the compared ones.</p></details> | <details><summary>8 pag...</summary><p>8 pages, 3 figures, 1 table, ICLMA 2023</p></details> |

